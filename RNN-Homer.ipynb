{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN-Homer.ipynb","provenance":[],"authorship_tag":"ABX9TyPBJnmNA1VTxbTNDkEcNkZL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"e17jL2jJRuHu","executionInfo":{"status":"ok","timestamp":1619975815024,"user_tz":-60,"elapsed":2224,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["\n","import tensorflow as tf\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","import numpy as np\n","import os\n","import time\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEvx2p8cR4vM","executionInfo":{"status":"ok","timestamp":1619975821070,"user_tz":-60,"elapsed":2548,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}},"outputId":"68c966d4-91df-48d3-964d-279f485d6dc9"},"source":["path_to_file = '/content/iliadaodysseia.txt'\n","\n","\n","#%%\n","\n","# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')\n","\n","\n","#%%\n","\n","print(text[:250])\n","\n","\n","#%%\n","\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')\n","\n","\n","\n","\n","\n","#%%\n","\n","ids_from_chars = preprocessing.StringLookup(\n","    vocabulary=list(vocab))\n","\n","\n","\n","#%%\n","\n","\n","#%%\n","\n","chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True,encoding='utf-8')\n","\n","\n","#%%\n","\n","def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n","\n","\n","#%%\n","\n","all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids\n","\n","\n","#%%\n","\n","ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n","\n","\n","#%%\n","\n","for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))\n","\n","\n","#%%\n","\n","seq_length = 100\n","examples_per_epoch = len(text)//(seq_length+1)\n","\n","\n","#%%\n","\n","sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))\n","\n","\n","#%%\n","\n","for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())\n","\n","\n","#%%\n","\n","def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text\n","\n","\n","#%%\n","\n","dataset = sequences.map(split_input_target)\n","\n","\n","#%%\n","\n","for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())\n","\n","\n","#%%\n","\n","# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset\n","\n","\n","#%%\n","\n","# Length of the vocabulary in chars\n","vocab_size = len(vocab)\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024\n","\n","\n","#%%\n","class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x\n","#%%\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Length of text: 1573038 characters\n","\n","Τη µάνητα, θεά, τραγουδά µας του ξακουστού Αχιλλέα,\n","\n","ανάθεµα τη, πίκρες που 'δωκε στους Αχαιούς περίσσιες\n","και πλήθος αντρειωµένες έστειλε ψυχές στον Άδη κάτω\n","παλικαριών, στους σκύλους ρίχνοντας να φανέ τα κορµιά τους\n","και στα όρνια ολούθε έτσι το θέλ\n","119 unique characters\n","\n","\n","Τ\n","η\n"," \n","µ\n","ά\n","ν\n","η\n","τ\n","α\n","tf.Tensor(\n","[b'\\n' b'\\xce\\xa4' b'\\xce\\xb7' b' ' b'\\xc2\\xb5' b'\\xce\\xac' b'\\xce\\xbd'\n"," b'\\xce\\xb7' b'\\xcf\\x84' b'\\xce\\xb1' b',' b' ' b'\\xce\\xb8' b'\\xce\\xb5'\n"," b'\\xce\\xac' b',' b' ' b'\\xcf\\x84' b'\\xcf\\x81' b'\\xce\\xb1' b'\\xce\\xb3'\n"," b'\\xce\\xbf' b'\\xcf\\x85' b'\\xce\\xb4' b'\\xce\\xac' b' ' b'\\xc2\\xb5'\n"," b'\\xce\\xb1' b'\\xcf\\x82' b' ' b'\\xcf\\x84' b'\\xce\\xbf' b'\\xcf\\x85' b' '\n"," b'\\xce\\xbe' b'\\xce\\xb1' b'\\xce\\xba' b'\\xce\\xbf' b'\\xcf\\x85' b'\\xcf\\x83'\n"," b'\\xcf\\x84' b'\\xce\\xbf' b'\\xcf\\x8d' b' ' b'\\xce\\x91' b'\\xcf\\x87'\n"," b'\\xce\\xb9' b'\\xce\\xbb' b'\\xce\\xbb' b'\\xce\\xad' b'\\xce\\xb1' b',' b'\\n'\n"," b'\\n' b'\\xce\\xb1' b'\\xce\\xbd' b'\\xce\\xac' b'\\xce\\xb8' b'\\xce\\xb5'\n"," b'\\xc2\\xb5' b'\\xce\\xb1' b' ' b'\\xcf\\x84' b'\\xce\\xb7' b',' b' '\n"," b'\\xcf\\x80' b'\\xce\\xaf' b'\\xce\\xba' b'\\xcf\\x81' b'\\xce\\xb5' b'\\xcf\\x82'\n"," b' ' b'\\xcf\\x80' b'\\xce\\xbf' b'\\xcf\\x85' b' ' b\"'\" b'\\xce\\xb4'\n"," b'\\xcf\\x89' b'\\xce\\xba' b'\\xce\\xb5' b' ' b'\\xcf\\x83' b'\\xcf\\x84'\n"," b'\\xce\\xbf' b'\\xcf\\x85' b'\\xcf\\x82' b' ' b'\\xce\\x91' b'\\xcf\\x87'\n"," b'\\xce\\xb1' b'\\xce\\xb9' b'\\xce\\xbf' b'\\xcf\\x8d' b'\\xcf\\x82' b' '\n"," b'\\xcf\\x80' b'\\xce\\xb5' b'\\xcf\\x81' b'\\xce\\xaf'], shape=(101,), dtype=string)\n","b\"\\n\\xce\\xa4\\xce\\xb7 \\xc2\\xb5\\xce\\xac\\xce\\xbd\\xce\\xb7\\xcf\\x84\\xce\\xb1, \\xce\\xb8\\xce\\xb5\\xce\\xac, \\xcf\\x84\\xcf\\x81\\xce\\xb1\\xce\\xb3\\xce\\xbf\\xcf\\x85\\xce\\xb4\\xce\\xac \\xc2\\xb5\\xce\\xb1\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85 \\xce\\xbe\\xce\\xb1\\xce\\xba\\xce\\xbf\\xcf\\x85\\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x8d \\xce\\x91\\xcf\\x87\\xce\\xb9\\xce\\xbb\\xce\\xbb\\xce\\xad\\xce\\xb1,\\n\\n\\xce\\xb1\\xce\\xbd\\xce\\xac\\xce\\xb8\\xce\\xb5\\xc2\\xb5\\xce\\xb1 \\xcf\\x84\\xce\\xb7, \\xcf\\x80\\xce\\xaf\\xce\\xba\\xcf\\x81\\xce\\xb5\\xcf\\x82 \\xcf\\x80\\xce\\xbf\\xcf\\x85 '\\xce\\xb4\\xcf\\x89\\xce\\xba\\xce\\xb5 \\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\x91\\xcf\\x87\\xce\\xb1\\xce\\xb9\\xce\\xbf\\xcf\\x8d\\xcf\\x82 \\xcf\\x80\\xce\\xb5\\xcf\\x81\\xce\\xaf\"\n","b'\\xcf\\x83\\xcf\\x83\\xce\\xb9\\xce\\xb5\\xcf\\x82\\n\\xce\\xba\\xce\\xb1\\xce\\xb9 \\xcf\\x80\\xce\\xbb\\xce\\xae\\xce\\xb8\\xce\\xbf\\xcf\\x82 \\xce\\xb1\\xce\\xbd\\xcf\\x84\\xcf\\x81\\xce\\xb5\\xce\\xb9\\xcf\\x89\\xc2\\xb5\\xce\\xad\\xce\\xbd\\xce\\xb5\\xcf\\x82 \\xce\\xad\\xcf\\x83\\xcf\\x84\\xce\\xb5\\xce\\xb9\\xce\\xbb\\xce\\xb5 \\xcf\\x88\\xcf\\x85\\xcf\\x87\\xce\\xad\\xcf\\x82 \\xcf\\x83\\xcf\\x84\\xce\\xbf\\xce\\xbd \\xce\\x86\\xce\\xb4\\xce\\xb7 \\xce\\xba\\xce\\xac\\xcf\\x84\\xcf\\x89\\n\\xcf\\x80\\xce\\xb1\\xce\\xbb\\xce\\xb9\\xce\\xba\\xce\\xb1\\xcf\\x81\\xce\\xb9\\xcf\\x8e\\xce\\xbd, \\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xcf\\x83\\xce\\xba\\xcf\\x8d\\xce\\xbb\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xcf\\x81\\xce\\xaf\\xcf\\x87\\xce\\xbd\\xce\\xbf\\xce\\xbd\\xcf\\x84\\xce\\xb1\\xcf\\x82 \\xce\\xbd\\xce\\xb1 \\xcf\\x86\\xce\\xb1\\xce\\xbd\\xce\\xad'\n","b\" \\xcf\\x84\\xce\\xb1 \\xce\\xba\\xce\\xbf\\xcf\\x81\\xc2\\xb5\\xce\\xb9\\xce\\xac \\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82\\n\\xce\\xba\\xce\\xb1\\xce\\xb9 \\xcf\\x83\\xcf\\x84\\xce\\xb1 \\xcf\\x8c\\xcf\\x81\\xce\\xbd\\xce\\xb9\\xce\\xb1 \\xce\\xbf\\xce\\xbb\\xce\\xbf\\xcf\\x8d\\xce\\xb8\\xce\\xb5 \\xce\\xad\\xcf\\x84\\xcf\\x83\\xce\\xb9 \\xcf\\x84\\xce\\xbf \\xce\\xb8\\xce\\xad\\xce\\xbb\\xce\\xb7\\xcf\\x83\\xce\\xb5 \\xce\\xbd\\xce\\xb1 \\xce\\xb3\\xce\\xaf\\xce\\xbd\\xce\\xb5\\xce\\xb9 \\xcf\\x84\\xcf\\x8c\\xcf\\x84\\xce\\xb5 \\xce\\xbf \\xe2\\x88\\x86\\xce\\xaf\\xce\\xb1\\xcf\\x82\\n\\xce\\xb1\\xcf\\x80' \\xcf\\x84\\xce\\xb7 \\xcf\\x83\\xcf\\x84\\xce\\xb9\\xce\\xb3\\xc2\\xb5\\xce\\xae \\xcf\\x80\\xce\\xbf\\xcf\\x85 \\xcf\\x80\\xcf\\x81\\xcf\\x89\\xcf\\x84\\xce\\xbf\\xcf\\x80\\xce\\xb9\\xce\\xac\\xcf\\x83\\xcf\\x84\"\n","b\"\\xce\\xb7\\xce\\xba\\xce\\xb1\\xce\\xbd \\xce\\xba\\xce\\xb1\\xce\\xb9 \\xcf\\x87\\xcf\\x8e\\xcf\\x81\\xce\\xb9\\xcf\\x83\\xce\\xb1\\xce\\xbd \\xce\\xbf\\xce\\xb9 \\xce\\xb4\\xcf\\x85\\xce\\xbf \\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82,\\n\\xcf\\x84\\xce\\xbf\\xcf\\x85 \\xce\\x91\\xcf\\x84\\xcf\\x81\\xce\\xad\\xce\\xb1 \\xce\\xbf \\xce\\xb3\\xce\\xb9\\xce\\xbf\\xcf\\x82 \\xce\\xbf \\xcf\\x83\\xcf\\x84\\xcf\\x81\\xce\\xb1\\xcf\\x84\\xce\\xbf\\xce\\xba\\xcf\\x81\\xce\\xac\\xcf\\x84\\xce\\xbf\\xcf\\x81\\xce\\xb1\\xcf\\x82 \\xce\\xba\\xce\\xb9 \\xce\\xbf \\xc2\\xb5\\xce\\xad\\xce\\xb3\\xce\\xb1\\xcf\\x82 \\xce\\x91\\xcf\\x87\\xce\\xb9\\xce\\xbb\\xce\\xbb\\xce\\xad\\xce\\xb1\\xcf\\x82.\\n\\xce\\xa0\\xce\\xbf\\xce\\xb9\\xce\\xbf\\xcf\\x82 \\xcf\\x84\\xce\\xac\\xcf\\x87\\xce\\xb1 \\xce\\xb1\\xcf\\x80' \\xcf\\x84\"\n","b\"\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\xb8\\xce\\xb5\\xce\\xbf\\xcf\\x8d\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\xad\\xcf\\x83\\xcf\\x80\\xcf\\x81\\xcf\\x89\\xce\\xbe\\xce\\xb5 \\xce\\xbd\\xce\\xb1 \\xc2\\xb5\\xcf\\x80\\xce\\xbf\\xcf\\x8d\\xce\\xbd\\xce\\xb5 \\xcf\\x83' \\xce\\xad\\xcf\\x84\\xce\\xbf\\xce\\xb9\\xce\\xb1 \\xce\\xb1\\xc2\\xb5\\xce\\xac\\xcf\\x87\\xce\\xb7;\\n\\xce\\xa4\\xce\\xbf\\xcf\\x85 \\xe2\\x88\\x86\\xce\\xaf\\xce\\xb1 \\xce\\xba\\xce\\xb1\\xce\\xb9 \\xcf\\x84\\xce\\xb7\\xcf\\x82 \\xce\\x9b\\xce\\xb7\\xcf\\x84\\xcf\\x8e\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\xad\\xcf\\x83\\xcf\\x80\\xcf\\x81\\xcf\\x89\\xce\\xbe\\xce\\xb5\\xce\\xbd \\xce\\xbf \\xce\\xb3\\xce\\xb9\\xce\\xbf\\xcf\\x82, \\xcf\\x80\\xce\\xbf\\xcf\\x85 \\xc2\\xb5\\xce\\xb5 \\xcf\\x84\"\n","Input : b\"\\n\\xce\\xa4\\xce\\xb7 \\xc2\\xb5\\xce\\xac\\xce\\xbd\\xce\\xb7\\xcf\\x84\\xce\\xb1, \\xce\\xb8\\xce\\xb5\\xce\\xac, \\xcf\\x84\\xcf\\x81\\xce\\xb1\\xce\\xb3\\xce\\xbf\\xcf\\x85\\xce\\xb4\\xce\\xac \\xc2\\xb5\\xce\\xb1\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85 \\xce\\xbe\\xce\\xb1\\xce\\xba\\xce\\xbf\\xcf\\x85\\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x8d \\xce\\x91\\xcf\\x87\\xce\\xb9\\xce\\xbb\\xce\\xbb\\xce\\xad\\xce\\xb1,\\n\\n\\xce\\xb1\\xce\\xbd\\xce\\xac\\xce\\xb8\\xce\\xb5\\xc2\\xb5\\xce\\xb1 \\xcf\\x84\\xce\\xb7, \\xcf\\x80\\xce\\xaf\\xce\\xba\\xcf\\x81\\xce\\xb5\\xcf\\x82 \\xcf\\x80\\xce\\xbf\\xcf\\x85 '\\xce\\xb4\\xcf\\x89\\xce\\xba\\xce\\xb5 \\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\x91\\xcf\\x87\\xce\\xb1\\xce\\xb9\\xce\\xbf\\xcf\\x8d\\xcf\\x82 \\xcf\\x80\\xce\\xb5\\xcf\\x81\"\n","Target: b\"\\xce\\xa4\\xce\\xb7 \\xc2\\xb5\\xce\\xac\\xce\\xbd\\xce\\xb7\\xcf\\x84\\xce\\xb1, \\xce\\xb8\\xce\\xb5\\xce\\xac, \\xcf\\x84\\xcf\\x81\\xce\\xb1\\xce\\xb3\\xce\\xbf\\xcf\\x85\\xce\\xb4\\xce\\xac \\xc2\\xb5\\xce\\xb1\\xcf\\x82 \\xcf\\x84\\xce\\xbf\\xcf\\x85 \\xce\\xbe\\xce\\xb1\\xce\\xba\\xce\\xbf\\xcf\\x85\\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x8d \\xce\\x91\\xcf\\x87\\xce\\xb9\\xce\\xbb\\xce\\xbb\\xce\\xad\\xce\\xb1,\\n\\n\\xce\\xb1\\xce\\xbd\\xce\\xac\\xce\\xb8\\xce\\xb5\\xc2\\xb5\\xce\\xb1 \\xcf\\x84\\xce\\xb7, \\xcf\\x80\\xce\\xaf\\xce\\xba\\xcf\\x81\\xce\\xb5\\xcf\\x82 \\xcf\\x80\\xce\\xbf\\xcf\\x85 '\\xce\\xb4\\xcf\\x89\\xce\\xba\\xce\\xb5 \\xcf\\x83\\xcf\\x84\\xce\\xbf\\xcf\\x85\\xcf\\x82 \\xce\\x91\\xcf\\x87\\xce\\xb1\\xce\\xb9\\xce\\xbf\\xcf\\x8d\\xcf\\x82 \\xcf\\x80\\xce\\xb5\\xcf\\x81\\xce\\xaf\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f69cTIsZE7Ka"},"source":["\n","model = MyModel(\n","    # Be sure the vocabulary size matches the `StringLookup` layers.\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)\n","\n","\n","#%%\n","\n","for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n","\n","\n","#%%\n","\n","model.summary()\n","\n","\n","#%%\n","\n","sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","\n","\n","#%%\n","\n","print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n","\n","\n","#%%\n","\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","\n","#%%\n","\n","example_batch_loss = loss(target_example_batch, example_batch_predictions)\n","mean_loss = example_batch_loss.numpy().mean()\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", mean_loss)\n","print(tf.exp(mean_loss).numpy())\n","\n","#%%\n","\n","model.compile(optimizer='adam', loss=loss)\n","\n","\n","#%%\n","\n","# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)\n","\n","\n","#%%\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rhZCdVDIEMCX"},"source":["\n","EPOCHS = 20\n","# history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n","history = model.fit(dataset, epochs=EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iSUd2CHgSLVm","executionInfo":{"status":"ok","timestamp":1619975917911,"user_tz":-60,"elapsed":445,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4KTJzP_TsIh","executionInfo":{"status":"ok","timestamp":1619975921546,"user_tz":-60,"elapsed":555,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJgnzUC0Twph","executionInfo":{"status":"ok","timestamp":1619976590670,"user_tz":-60,"elapsed":3731,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}},"outputId":"7e48d913-365d-4b38-b0b8-ebab105cd72f"},"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['Και είπε τοτε '])\n","result = [next_char]\n","\n","for n in range(2000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Και είπε τοτε µάνταλο' και πήδησαν οι δούλες\n"," να τρέξει στα καράβια πρόθυµα στο αρχοντικό σου µέσα\n","µε τον τρανό, κουράγιο του άκουσεν ο Πάτροκλος και πλάντου,\n"," και µια µωρό το πρώτα σύγνεφο πηδούν να βγουν πάχτη,\n","\n","που οι δυο τους Αχαιούς, που εγώ τη φλέπνο µας, στον κάµπο, µες στο νου του.\n","Κι όπως τον είδε, ο θείος Αγαδήνορας, και βούλιαξαν στον κάµπο·\n","στον ώµο ο ξεχωρίζεις τότε µας, που από κριγιούς κουράγιο.\n"," Κάθε φορά η κουλήλιος λάθεψα, και µόνο αλήθεια ζεύεικες κρατούσε το κοντάρι,\n","το γιο να µένουν άκουσε και µου' κει ποι όλη έστεια του Κρόνου ο γιος του Αρχίσου,\n"," σε γιο τους Τρώες στους λιονταρόκαρδους υγιούς του Ατρέα και ρίχτες,\n","πια µην ντραπείς και µαύρη µοίρα,\n","να ίδες βοσκοί που στέκουνταν στο φως τα πλήθια κράζει:\n","« Ποιος τότε αναγελώντας τον, να ξεπεράσει Μειείτε,\n","να µη γλιτώσει, υγιούς εγώ δε σώκουµαι στον κόχτιο αµαξουνό, να σέρνει\n","καρτέρι' είµαι τ' αρνιά τους βρήκαν και τις κόρες του, του ρήγα τα χοριάζει,\n","ως που πια τα φουσάτα παίρνοντας την πέρφανη καρδιά του µόνο\n","και µεις να τρως, να κυνούµε.»\n","Έτσι µιλούσε, κι όλοι τους οι Αργίτες οι αρχοστάτες,\n","\n","µιαν αϊτε έδες να 'ρχεται! Μα ως πια µπροστά τους,\n","γι' αυτόν, πρόφταιναν ακριµµένοι.\n"," Μα το λιοπλήθιο τύχα ο θάνατος θ' ακούσεις να διαγείρει'\n","του Πηλεγόνα Καλυδώνα µην αξετίµητο, µε κεφαλή σκεπάζει\n","κι όλα µαζί τρεις, παρθαρούσατε' για τους Αργίτες τέλες,\n","στο χώµα τραπηγάρισε' τον Αχιλλέα το λύκο'\n","κι ουδέ που το 'κρυψε, που τύχει να 'ρθει µέσα ξέροντας ψωµί αποµιών του πλούτη\n","κι από την άλλη, απ' το κοντάρι του στο χαλκοκράνη κίνη,\n","πάνω απ' τη χέρια εσήµωσε' τι οι αθάνατοι σου 'χε ρηγάρχες· τι τιµήσει\n","του κάκου! βγάζοντας τα χέρια του δροκιόλα, βοϊδοµάτο,\n","στο καστροτείχι του άψεγουδα γιους του Ατρέα,\n","πολλην τον γνωριστεύοντάς τον:\n","«Για σα θε ιδεί, να γύρεις στην Αλόγιαστα, τον Φθιώνα,\n","ακριβό δικό σου λες, και κράζαν έπειτα τον Ορυστό, τι απάνω του όσο ζουν στα ουράνια\n","\n","λεν η ξωθιογηλούσα µάχη.\n","\n","\n","Στους ζίβους τους µνηστήρες που 'στεκό θαρρώ θα λαφροκλύβεται να βρει το θάνατο να δώσει χέρι τώρα,\n"," και µε τους Αλογάρηδες αρ \n","\n","________________________________________________________________________________\n","\n","Run time: 3.227311134338379\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o2mHIIprDpQu","executionInfo":{"status":"ok","timestamp":1619975828537,"user_tz":-60,"elapsed":446,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["class CustomTraining(MyModel):\n","  @tf.function\n","  def train_step(self, inputs):\n","      inputs, labels = inputs\n","      with tf.GradientTape() as tape:\n","          predictions = self(inputs, training=True)\n","          loss = self.loss(labels, predictions)\n","      grads = tape.gradient(loss, model.trainable_variables)\n","      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      return {'loss': loss}"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"93q9cU2OFZYi","executionInfo":{"status":"ok","timestamp":1619975840961,"user_tz":-60,"elapsed":437,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["model = CustomTraining(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KuwEVDaiDqON","executionInfo":{"status":"ok","timestamp":1619975848900,"user_tz":-60,"elapsed":468,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}}},"source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tDgeXEwFb9W","executionInfo":{"status":"ok","timestamp":1619976482375,"user_tz":-60,"elapsed":549271,"user":{"displayName":"Akis Loumpourdis","photoUrl":"","userId":"18415315932649052405"}},"outputId":"21cfa36b-feef-462f-da3e-24fd02f079dc"},"source":["model.fit(dataset, epochs=20)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","243/243 [==============================] - 27s 106ms/step - loss: 1.8087\n","Epoch 2/20\n","243/243 [==============================] - 27s 107ms/step - loss: 1.4921\n","Epoch 3/20\n","243/243 [==============================] - 28s 110ms/step - loss: 1.3377\n","Epoch 4/20\n","243/243 [==============================] - 28s 109ms/step - loss: 1.2478\n","Epoch 5/20\n","243/243 [==============================] - 27s 109ms/step - loss: 1.1827\n","Epoch 6/20\n","243/243 [==============================] - 28s 110ms/step - loss: 1.1303\n","Epoch 7/20\n","243/243 [==============================] - 28s 109ms/step - loss: 1.0833\n","Epoch 8/20\n","243/243 [==============================] - 27s 108ms/step - loss: 1.0398\n","Epoch 9/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.9970\n","Epoch 10/20\n","243/243 [==============================] - 28s 111ms/step - loss: 0.9545\n","Epoch 11/20\n","243/243 [==============================] - 28s 111ms/step - loss: 0.9153\n","Epoch 12/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.8706\n","Epoch 13/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.8314\n","Epoch 14/20\n","243/243 [==============================] - 27s 108ms/step - loss: 0.7960\n","Epoch 15/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.7508\n","Epoch 16/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.7137\n","Epoch 17/20\n","243/243 [==============================] - 28s 109ms/step - loss: 0.6807\n","Epoch 18/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.6563\n","Epoch 19/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.6312\n","Epoch 20/20\n","243/243 [==============================] - 27s 109ms/step - loss: 0.6117\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fbcf67c2310>"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"F19ELvGPFwx3"},"source":[""],"execution_count":null,"outputs":[]}]}