{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "GPT2-Homer-finetuned.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rstGOiprFMQP",
    "outputId": "152df88f-ba0f-489e-9819-d622d948bbdf"
   },
   "source": [
    "!pip install transformers==4.2.2\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rY3tHnLDJvl6"
   },
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nikokons/gpt2-greek\")\n",
    "\n",
    "train_path = '/content/iliadaodysseia.txt'\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pEkyWQTKKsGx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c993d8ff-fbdb-4cf9-8db2-b38bed17053a"
   },
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,data_collator\n",
    "\n",
    "train_dataset,data_collator = load_dataset(train_path,tokenizer)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7PITqSxLFeI",
    "outputId": "533cf2c4-27a3-405a-c2dc-0258a0677487"
   },
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(\"nikokons/gpt2-greek\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-homer\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved\n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "\n",
    "   \n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "pEE2F1_cLTX4",
    "outputId": "78428a2d-773d-40b1-8bf0-ef84ac233ea8"
   },
   "source": [
    "trainer.train()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_WtZNzohLY_c"
   },
   "source": [
    "trainer.save_model()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QHW4-yU7L40E"
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline('text-generation',model='./gpt2-homer', tokenizer='nikokons/gpt2-greek')\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JhasdSGBMK8p",
    "outputId": "21108fb8-f1f4-4461-b7bb-dc954471429d"
   },
   "source": [
    "result = generator('Και τότε ο Οδυσσέας ',\n",
    "                   do_sample=True, \n",
    "    max_length=200, \n",
    "    top_p=0.92, \n",
    "    top_k=0\n",
    "                    )[0]['generated_text']\n",
    "# print(result)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OTQywEgVWsrm",
    "outputId": "5a013f7e-dfec-4540-a39e-34ed42b19d8e"
   },
   "source": [
    "print(result)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyZLPIyqXR0i",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Output generated:\n",
    "\n",
    "Και τότε ο Οδυσσέας  του απηλογήθη κι είπε:\n",
    "«Και τώρα, πηγαίνοντας στους θεούς τ' αρνιά τρανή σου πια βουλή δεν 'ρθε,\n",
    "το ρίξει ο άλλος, ο Ευρύλοχος, ο Μενέλαος µε το σπήλιο,\n",
    "γιατί απ' τις πιοτσιάδες απαράλλαχτες του είναι πια τόσο πως δεν σου διώχεις.\n",
    "Κι αυτοί τα χωράφια και τα νερά των σκλάβων ξεκάνουν\n",
    "και σκόρπισαν στο Παρπησσό στη γη τον πόλεµο, κι ο Μενέλαος τα φαγιά και το ξάρπιο\n",
    "σαν τα σπαθιά τους' το ψηλό κρασί χτυπιούνται και τα κροσσωµένη ψυχανθές,\n",
    "και τα πολλά σε κάθιζαν στο ανάµερο οχτρεύει;\n",
    "\n",
    "Πο γιεσός τους πολλούς δίνει' κι\n",
    "\n",
    "\n",
    "The output can be improved, while it is syntactically not bad , some of the word sequences are not meaningful\n"
   ]
  }
 ]
}